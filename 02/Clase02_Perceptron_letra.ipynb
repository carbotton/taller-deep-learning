{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carbotton/taller-deep-learning/blob/main/02/Clase02_Perceptron_letra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFDq4IxV9kjk"
      },
      "source": [
        "# Mi primera red neuronal 🚀\n",
        "\n",
        "En esta notebook, vamos a explorar la implementación de una red neuronal simple conocida como perceptrón. Un perceptrón es una unidad básica de una red neuronal que puede utilizarse para resolver problemas de clasificación binaria, como las funciones lógicas.\n",
        "\n",
        "## Objetivos de Aprendizaje\n",
        "\n",
        "Al final de esta notebook, serás capaz de:\n",
        "\n",
        "1. Implementar un perceptrón simple en con las funciones lógicas (AND, OR, XOR) vistas en clase de dos formas diferentes:\n",
        "    - Utilizando multiplicación de matrices ($sgn\\left( X \\, W \\right)$).\n",
        "    - Utilizando el sesgo ($sgn\\left( X \\, W + b \\right)$).\n",
        "2. [Opcional] Implementar el resto de las funciones lógicas (NAND, NOR, XNOR) utilizando perceptrones.\n",
        "3. Implementar una Perceptrón Multicapa (MLP) para resolver el problema XOR.\n",
        "4. [Opcional] Implementar un MLP para resolver las todas las funciones lógicas al mismo tiempo (AND, OR, XOR).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eURfGgTu9kjm"
      },
      "source": [
        "## Implementación de un Perceptrón\n",
        "\n",
        "Un perceptrón es una unidad básica de una red neuronal que puede utilizarse para resolver problemas de clasificación binaria.\n",
        "\n",
        "$$\n",
        "\\mathcal{P}(x; w) = sgn(x\\, w) = sgn\\left( \\sum_i x_i w_i \\right)\n",
        "\\quad x, w \\in \\mathbb{R}^m\n",
        "$$\n",
        "con\n",
        "$$\n",
        " sgn(u) =\n",
        "  \\begin{cases}\n",
        "   +1 & \\text{if } u \\geq 0 \\\\\n",
        "   -1 & \\text{if } u < 0\n",
        "  \\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8h6NsrG9kjn"
      },
      "source": [
        "En forma vectorial\n",
        "\n",
        "$$\\mathcal{P}(X; W) = sgn\\left( X \\, W \\right) \\quad X \\in \\mathbb{R}^{(n,m)}, \\, W \\in \\mathbb{R}^{(m,1)}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy-R1b0biyCy"
      },
      "source": [
        "### AND\n",
        "\n",
        "La función lógica AND es una función que toma dos entradas binarias y devuelve 1 si ambas entradas son 1, y 0 en cualquier otro caso.\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 0   |\n",
        "| 0     | 1     | 0   |\n",
        "| 1     | 0     | 0   |\n",
        "| 1     | 1     | 1   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PF0WQGliyC0"
      },
      "source": [
        "#### Implementación con multiplicación de matrices\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "  0 & 0 & 1 \\\\\n",
        "  0 & 1 & 1 \\\\\n",
        "  1 & 0 & 1 \\\\\n",
        "  1 & 1 & 1 \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "\\textbf{AND}\\left( X \\right) =\n",
        " \\begin{pmatrix}\n",
        "  -1 \\\\\n",
        "  -1 \\\\\n",
        "  -1 \\\\\n",
        "  1  \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "n = 4\n",
        "$$\n",
        "\n",
        "> Notar que los valores esperados son -1 y 1 en lugar de 0 y 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPwofV509kjo"
      },
      "source": [
        "$$\n",
        "\\textbf{AND}\\left(X \\right) = sgn\\left( X \\,   \n",
        "    \\begin{pmatrix}\n",
        "      .5 \\\\\n",
        "      .5 \\\\\n",
        "      -1 \\\\\n",
        "    \\end{pmatrix} \\right)\n",
        "    \\quad\n",
        "    m = 3\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AQ1pVQ_ZiyC2"
      },
      "outputs": [],
      "source": [
        "# Vamos a trabajar con PyTorch (tensores) para las operaciones matriciales\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUTXmM6uiyC3"
      },
      "source": [
        "Definimos la función `sgn` que aplica la función signo a un número.\n",
        "\n",
        "> Nota: pytorch tiene una función `torch.sign` pero difiere cuando la entrada es 0. En este caso, `torch.sign` devuelve 0 y `sgn` devuelve 1.\n",
        "Más información en: https://pytorch.org/docs/stable/generated/torch.sign.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GFIGgor5iyC4"
      },
      "outputs": [],
      "source": [
        "def sgn(x):\n",
        "    return torch.where(x >= 0, 1.0, -1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQc483s6iyC5"
      },
      "source": [
        "Definimos `X` y `W` como tensores de pytorch, es importante definir el tipo de dato como `torch.float32` para que las operaciones matriciales se realicen correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFbiqXxCiyC6",
        "outputId": "d4eb98ac-1f0b-490b-8456-0688082933a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0000],\n",
              "        [-0.5000],\n",
              "        [-0.5000],\n",
              "        [ 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X = torch.tensor([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "\n",
        "# TODO\n",
        "W_and = torch.tensor([[.5], [.5], [-1]])  # con el . ya inferi que es un float32 a diferencia del de arriba\n",
        "\n",
        "torch.matmul(X, W_and)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA95jDbNiyC7"
      },
      "source": [
        "Por último, calculamos el resultado de la función AND."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_rDVFBtiyC7",
        "outputId": "259c9e26-76a3-403f-a825-72da3ef27677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND(X) = tensor([[-1.],\n",
            "        [-1.],\n",
            "        [-1.],\n",
            "        [ 1.]])\n"
          ]
        }
      ],
      "source": [
        "def AND(Input):\n",
        "    # TODO\n",
        "    return  sgn(torch.matmul(Input, W_and))\n",
        "\n",
        "print(f\"{AND(X) = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cXJp0oziyC8"
      },
      "source": [
        "Vemos que el resultado es el esperado.\n",
        "\n",
        "$$\n",
        "\\textbf{AND}\\left( X \\right) =\n",
        " \\begin{pmatrix}\n",
        "  -1 \\\\\n",
        "  -1 \\\\\n",
        "  -1 \\\\\n",
        "  1  \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3TDOH7_iyC9",
        "outputId": "117fb857-302d-45ae-fc16-ee3eb2744c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "res = tensor([-1.])\n"
          ]
        }
      ],
      "source": [
        "res = AND(torch.tensor([1, 0, 1], dtype=torch.float32))\n",
        "print(f\"{res = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_lpqJuTiyC9"
      },
      "source": [
        "#### Implementación con sesgo (X W + b)\n",
        "\n",
        "Ahora vamos a implementar la función AND utilizando un sesgo, es decir agregando un término adicional a la multiplicación de matrices.\n",
        "\n",
        "Por lo cual nuestro X ahora es de la forma:\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "  0 & 0 \\\\\n",
        "  0 & 1 \\\\\n",
        "  1 & 0 \\\\\n",
        "  1 & 1 \\\\\n",
        " \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Y nuestro W y b son:\n",
        "\n",
        "$$\n",
        "W = \\begin{pmatrix}\n",
        "  .5 \\\\\n",
        "  .5 \\\\\n",
        "  \\end{pmatrix}\n",
        "\\qquad\n",
        "b = -1\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0TQYcppyiyC-"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "\n",
        "# TODO\n",
        "W_and = torch.tensor([[.5], [.5]])\n",
        "b = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9412INI9iyC_",
        "outputId": "e79fc5e6-4885-43c9-f92d-b9b8e00f6491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND(X) = tensor([[-1.],\n",
            "        [-1.],\n",
            "        [-1.],\n",
            "        [ 1.]])\n"
          ]
        }
      ],
      "source": [
        "def AND(Input):\n",
        "    # TODO\n",
        "    return sgn(torch.matmul(Input, W_and) + b)\n",
        "\n",
        "print(f\"{AND(X) = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LujJ8OxEiyC_"
      },
      "source": [
        "Notar `b` hace brodcasting, ya que es un escalar y `X` es una matriz.\n",
        "\n",
        "Más información en:\n",
        "- https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
        "- https://pytorch.org/docs/stable/notes/broadcasting.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNm3rY4MiyDA",
        "outputId": "4404a55a-913c-4f43-ea0d-255c857769ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.],\n",
              "        [-1.],\n",
              "        [-1.],\n",
              "        [ 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "AND(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n32MUT6eiyDA"
      },
      "source": [
        "### OR\n",
        "\n",
        "La función lógica OR es una función que toma dos entradas binarias y devuelve 1 si al menos una de las entradas es 1, y 0 en cualquier otro caso.\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 0   |\n",
        "| 0     | 1     | 1   |\n",
        "| 1     | 0     | 1   |\n",
        "| 1     | 1     | 1   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eYVV9zriyDB"
      },
      "source": [
        "#### Implementación con multiplicación de matrices\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "  0 & 0 & 1 \\\\\n",
        "  0 & 1 & 1 \\\\\n",
        "  1 & 0 & 1 \\\\\n",
        "  1 & 1 & 1 \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "\\textbf{OR}\\left( X \\right) =\n",
        " \\begin{pmatrix}\n",
        "  -1 \\\\\n",
        "  1 \\\\\n",
        "  1 \\\\\n",
        "  1  \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "n = 4\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNHJ__GwiyDB"
      },
      "source": [
        "$$\n",
        "\\textbf{OR}\\left(X \\right) = sgn\\left( X \\,   \n",
        "    \\begin{pmatrix}\n",
        "      ? \\\\\n",
        "      ? \\\\\n",
        "      ? \\\\\n",
        "    \\end{pmatrix} \\right)\n",
        "    \\quad\n",
        "    m = 3\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC431_vCiyDC",
        "outputId": "58c25445-18be-4274-d4fd-7d3cd9b13430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR(X) = tensor([[-1.],\n",
            "        [ 1.],\n",
            "        [ 1.],\n",
            "        [ 1.]])\n"
          ]
        }
      ],
      "source": [
        "X = torch.tensor([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "\n",
        "# TODO\n",
        "W_nor = torch.tensor([[1], [1], [-1]], dtype=torch.float32)\n",
        "\n",
        "def OR(Input):\n",
        "    # TODO\n",
        "    return sgn(torch.matmul(Input, W_nor))\n",
        "\n",
        "\n",
        "print(f\"{OR(X) = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHe8_nqhiyDD"
      },
      "source": [
        "#### Implementación con sesgo (X W + b)\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "  0 & 0 \\\\\n",
        "  0 & 1 \\\\\n",
        "  1 & 0 \\\\\n",
        "  1 & 1 \\\\\n",
        " \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Y nuestro W y b son:\n",
        "\n",
        "$$\n",
        "W = \\begin{pmatrix}\n",
        "  ? \\\\\n",
        "  ? \\\\\n",
        "  \\end{pmatrix}\n",
        "\\qquad\n",
        "b = ?\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZu3aAxBiyDE",
        "outputId": "c19fe8cf-5fad-46e0-aea6-024a26b9fb03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR(X) = tensor([[-1.],\n",
            "        [ 1.],\n",
            "        [ 1.],\n",
            "        [ 1.]])\n"
          ]
        }
      ],
      "source": [
        "# TODO...\n",
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "W_or = torch.tensor([[1], [1]], dtype=torch.float32)\n",
        "b = torch.tensor(-1)\n",
        "\n",
        "def OR(Input):\n",
        "    # TODO\n",
        "    return sgn(torch.matmul(Input, W_or) + b)\n",
        "\n",
        "\n",
        "print(f\"{OR(X) = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu2BYKj9iyDF"
      },
      "source": [
        "### XOR\n",
        "\n",
        "La función lógica XOR es una función que toma dos entradas binarias y devuelve 1 si las entradas son diferentes, y 0 si son iguales.\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 0   |\n",
        "| 0     | 1     | 1   |\n",
        "| 1     | 0     | 1   |\n",
        "| 1     | 1     | 0   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXm7H4aDiyDG"
      },
      "source": [
        "#### Implementación con multiplicación de matrices\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "  0 & 0 & 1 \\\\\n",
        "  0 & 1 & 1 \\\\\n",
        "  1 & 0 & 1 \\\\\n",
        "  1 & 1 & 1 \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "\\textbf{XOR}\\left( X \\right) =\n",
        " \\begin{pmatrix}\n",
        "  -1 \\\\\n",
        "  1 \\\\\n",
        "  1 \\\\\n",
        "  -1  \\\\\n",
        " \\end{pmatrix}\n",
        "\\qquad\n",
        "n = 4\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDBUmkUkiyDG"
      },
      "source": [
        "$$\n",
        "\\textbf{XOR}\\left(X \\right) = sgn\\left( X \\,   \n",
        "    \\begin{pmatrix}\n",
        "      ? \\\\\n",
        "      ? \\\\\n",
        "      ? \\\\\n",
        "    \\end{pmatrix} \\right)\n",
        "    \\quad\n",
        "    m = 3\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vadaYk83iyDH",
        "outputId": "bf2f7b82-2484-4504-89f0-da2d3875bca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR(X) = tensor([[-1.],\n",
            "        [ 1.],\n",
            "        [-1.],\n",
            "        [-1.]])\n"
          ]
        }
      ],
      "source": [
        "# TODO...\n",
        "X = torch.tensor([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "W_xor = torch.tensor([[-1], [1], [-1]], dtype=torch.float32)\n",
        "\n",
        "def XOR(Input):\n",
        "    # TODO\n",
        "    return sgn(torch.matmul(Input, W_xor))\n",
        "\n",
        "\n",
        "print(f\"{XOR(X) = }\")\n",
        "\n",
        "#### NO SE PUEDE c:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3STuwPbiyDI"
      },
      "source": [
        "### [Opcional] Implementar el resto de las funciones lógicas (NAND, NOR, XNOR) utilizando perceptrones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J54I_Hz9iyDI"
      },
      "source": [
        "#### NAND\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 1   |\n",
        "| 0     | 1     | 1   |\n",
        "| 1     | 0     | 1   |\n",
        "| 1     | 1     | 0   |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5juuU9FiyDJ",
        "outputId": "f9df2673-5f91-4f65-d1d9-9531ba2d7a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAND(X) = tensor([[ 1.],\n",
            "        [ 1.],\n",
            "        [ 1.],\n",
            "        [-1.]])\n"
          ]
        }
      ],
      "source": [
        "# TODO...\n",
        "X = torch.tensor([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "W_NAND = torch.tensor([[-1], [-1], [1]], dtype=torch.float32)\n",
        "#result (1, 1, 1, 0)\n",
        "\n",
        "def NAND(Input):\n",
        "    # TODO\n",
        "    return sgn(torch.matmul(Input, W_NAND))\n",
        "\n",
        "\n",
        "print(f\"{NAND(X) = }\")\n",
        "\n",
        "# esta bien, para nosotros el -1 es el 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6lfiaTWiyDJ"
      },
      "source": [
        "#### NOR\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 1   |\n",
        "| 0     | 1     | 0   |\n",
        "| 1     | 0     | 0   |\n",
        "| 1     | 1     | 0   |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "G2o0solAiyDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5956fa99-d3f6-4d35-c8f8-62180de8f2ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOR(X) = tensor([[ 1.],\n",
            "        [-1.],\n",
            "        [-1.],\n",
            "        [-1.]])\n"
          ]
        }
      ],
      "source": [
        "# TODO...\n",
        "\n",
        "X = torch.tensor([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "W_NOR = torch.tensor([[-1], [-1], [0]], dtype=torch.float32)\n",
        "#result (1, 0, 0, 0) ~ (1, -1, -1, -1)\n",
        "\n",
        "def NOR(Input):\n",
        "    # TODO\n",
        "    return sgn(torch.matmul(Input, W_NOR))\n",
        "\n",
        "\n",
        "print(f\"{NOR(X) = }\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0LAAq3GiyDK"
      },
      "source": [
        "#### NXOR\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|-------|-------|-----|\n",
        "| 0     | 0     | 1   |\n",
        "| 0     | 1     | 0   |\n",
        "| 1     | 0     | 0   |\n",
        "| 1     | 1     | 1   |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "X9rRdKMRiyDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597162b9-a009-4bc8-fcad-e6fbcc9c905c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NXOR(X) = tensor([[ 1.],\n",
            "        [-1.],\n",
            "        [-1.],\n",
            "        [-1.]])\n"
          ]
        }
      ],
      "source": [
        "# TODO...\n",
        "\n",
        "X = torch.tensor([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
        "W_NXOR = torch.tensor([[-1], [-2], [0]], dtype=torch.float32)\n",
        "#result (1, 0, 0, 1) ~ (1, -1, -1, 1)\n",
        "\n",
        "def NXOR(Input):\n",
        "    # TODO\n",
        "    return sgn(torch.matmul(Input, W_NXOR))\n",
        "\n",
        "\n",
        "print(f\"{NXOR(X) = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VThOpbgMiyDL"
      },
      "source": [
        "## XOR con Perceptrón Multicapa (MLP)\n",
        "\n",
        "Para resolver el problema XOR, necesitamos una red neuronal más compleja, como una Perceptrón Multicapa (MLP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ouwpK-Y0iyD4"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# De la tabla de verdad\n",
        "# Entradas\n",
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "# Salidas esperadas\n",
        "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UDmv5W3oiyD5"
      },
      "outputs": [],
      "source": [
        "# Definimos el modelo\n",
        "\n",
        "class XORNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XORNet, self).__init__()\n",
        "        self.input = nn.Linear(2, 2) # 2 neuronas\n",
        "        self.output = nn.Linear(2, 1) # tomo las 2 anteriores y saco 1 resultado\n",
        "\n",
        "    def forward(self, x):\n",
        "        # funcion de activacion para desdibujar linealidad\n",
        "        x = torch.sigmoid(self.input(x))\n",
        "        x = torch.sigmoid(self.output(x))\n",
        "        return x\n",
        "\n",
        "# Aternativa pipeline ; equivalente a lo que hicimos en forward()\n",
        "xor_seq = torch.nn.Sequential(\n",
        "    nn.Linear(2, 2),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(2, 1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VlRjcD2SiyD6"
      },
      "outputs": [],
      "source": [
        "# Instanciamos\n",
        "model = XORNet()  # o en la alternativa: model = xor_seq\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.5) # actualiza los pesos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmP36VSxiyD7",
        "outputId": "01a0405b-83c5-49a2-cec1-03617d355382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1000/epochs], Loss: 0.6927\n",
            "Epoch [2000/epochs], Loss: 0.1890\n",
            "Epoch [3000/epochs], Loss: 0.0190\n",
            "Epoch [4000/epochs], Loss: 0.0096\n",
            "Epoch [5000/epochs], Loss: 0.0064\n",
            "Epoch [6000/epochs], Loss: 0.0048\n",
            "Epoch [7000/epochs], Loss: 0.0038\n",
            "Epoch [8000/epochs], Loss: 0.0032\n",
            "Epoch [9000/epochs], Loss: 0.0027\n",
            "Epoch [10000/epochs], Loss: 0.0024\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "epochs = 10_000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # training mode\n",
        "\n",
        "    output = model(X) # aplica lo que definimos en el forward\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()  # reseteamos los gradientes\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 1_000 == 0:\n",
        "        print(f\"Epoch [{(epoch + 1)}/epochs], Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVmEf0fqiyD8",
        "outputId": "7d07ba22-13bc-4f16-ae53-105a817240e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0028],\n",
            "        [0.9979],\n",
            "        [0.9979],\n",
            "        [0.0024]])\n",
            "tensor([[0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0]])\n"
          ]
        }
      ],
      "source": [
        "# evaluando el modelo\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(X)\n",
        "    print(output) # tiene que dar cerca de (0, 1, 1, 0) (xor)\n",
        "    output = torch.where(output < 0.5, 0, 1)\n",
        "    print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv3fXs62iyD8"
      },
      "source": [
        "## [Opcional] Implementar una MLP para resolver todas las funciones lógicas al mismo tiempo (AND, OR y XOR).\n",
        "\n",
        "\n",
        "| $x_1$ | $x_2$ | $y_{AND}$ | $y_{OR}$ | $y_{XOR}$ |\n",
        "|-------|-------|-----------|----------|-----------|\n",
        "| 0     | 0     | 0         | 0        | 0         |\n",
        "| 0     | 1     | 0         | 1        | 1         |\n",
        "| 1     | 0     | 0         | 1        | 1         |\n",
        "| 1     | 1     | 1         | 1        | 0         |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LiFpQLcziyD9"
      },
      "outputs": [],
      "source": [
        "# Entradas\n",
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "# Salidas esperadas\n",
        "y = torch.tensor([[0, 0, 0], [0, 1, 1], [0, 1, 1], [1, 1, 0]], dtype=torch.float32)\n",
        "\n",
        "# TODO...\n",
        "\n",
        "# Definimos el modelo\n",
        "and_or_xor_seq = torch.nn.Sequential(\n",
        "    nn.Linear(2, 2),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(2, 3),\n",
        "    nn.Sigmoid()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciamos\n",
        "model = and_or_xor_seq\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy\n",
        "optimizer = optim.SGD(model.parameters(), lr=1) # actualiza los pesos"
      ],
      "metadata": {
        "id": "VSEvNILxAxx7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "epochs = 10_000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # training mode\n",
        "\n",
        "    output = model(X) # aplica lo que definimos en el forward\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()  # reseteamos los gradientes\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 1_000 == 0:\n",
        "        print(f\"Epoch [{(epoch + 1)}/epochs], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT3aovdg9SiN",
        "outputId": "ee167f1b-ee4a-413d-d6ec-67c1095b13b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1000/epochs], Loss: 0.0715\n",
            "Epoch [2000/epochs], Loss: 0.0210\n",
            "Epoch [3000/epochs], Loss: 0.0119\n",
            "Epoch [4000/epochs], Loss: 0.0083\n",
            "Epoch [5000/epochs], Loss: 0.0063\n",
            "Epoch [6000/epochs], Loss: 0.0051\n",
            "Epoch [7000/epochs], Loss: 0.0043\n",
            "Epoch [8000/epochs], Loss: 0.0037\n",
            "Epoch [9000/epochs], Loss: 0.0032\n",
            "Epoch [10000/epochs], Loss: 0.0029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluando el modelo\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(X)\n",
        "    print(output) # tiene que dar cerca de (0, 1, 1, 0) (xor)\n",
        "    output = torch.where(output < 0.5, 0, 1)\n",
        "    print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFWIkzvC9Uky",
        "outputId": "e136ad91-9b23-4916-f636-d6d1cdb79980"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5.0181e-06, 3.1031e-03, 6.6862e-03],\n",
            "        [1.2291e-03, 9.9872e-01, 9.9512e-01],\n",
            "        [1.2291e-03, 9.9872e-01, 9.9512e-01],\n",
            "        [9.9698e-01, 1.0000e+00, 6.9469e-03]])\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 1, 1],\n",
            "        [0, 1, 1],\n",
            "        [1, 1, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hPo7GVVjAkmo"
      },
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}